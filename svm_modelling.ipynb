{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categorical_features(dt: pd.DataFrame):\n",
    "    \"\"\"Use sklearns OneHotEncoder to encode categorical features\n",
    "\n",
    "    Args:\n",
    "        dt (pd.DataFrame): cleaned dataframe\n",
    "\n",
    "    Returns:\n",
    "        df_merged: dataframe of encoded categorical features as well as unchanged numerical ones\n",
    "    \"\"\"\n",
    "    dt.drop(\"id\", axis=1, inplace=True)\n",
    "    text_columns = dt.select_dtypes(include=object).columns.tolist() #lists categorical features\n",
    "    encoded_df = pd.DataFrame() # init empty dataframe to sequentially add encoded columns to\n",
    "    for col in text_columns: #iterate through categorical features\n",
    "        enc = OneHotEncoder(sparse_output=False) # init one hot encoder\n",
    "        col_data = dt[[col]] # select column data\n",
    "        enc_col = pd.DataFrame(enc.fit_transform(col_data), columns= enc.categories_) # fit encoder and transform data. Then convert to dataframe\n",
    "        encoded_df = pd.concat([encoded_df, enc_col], axis=1) # add to encoded_df\n",
    "       \n",
    "           \n",
    "    numeric_df= dt.select_dtypes(include=np.number) # select dataframe of numerical columns\n",
    "    encoded_df.reset_index(inplace=True) # reset indices of both dataframes so they can be merged on the index column\n",
    "    numeric_df.reset_index(inplace=True)\n",
    "    df_merged = pd.merge(encoded_df, numeric_df, left_index=True, right_index=True) # merge numeric with encoded categorical\n",
    "    df_merged.columns = df_merged.columns.astype(str) # cast column names to string, SVM doesn't like them otherwie\n",
    "    df_merged = df_merged.drop(\"('index',)\", axis = 1) # remove index columns \n",
    "    df_merged = df_merged.drop(\"index\", axis = 1)\n",
    "\n",
    "    return df_merged # return merged dataframe now ready for training\n",
    " \n",
    " \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(features, labels):\n",
    "    # generate train/test split whilst using stratify parameter to ensure the stroke class is equally represented in train and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42, stratify = labels)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svm(x_train, y_train):\n",
    "    \"\"\"Train SVM on train set\n",
    "\n",
    "    Args:\n",
    "        x_train \n",
    "        y_train \n",
    "\n",
    "    Returns:\n",
    "        SVC_Gaussian: Trained Support vector machine with rbf kernel \n",
    "    \"\"\"\n",
    "    SVC_Gaussian = SVC(kernel=\"rbf\")\n",
    "    SVC_Gaussian.fit(x_train, y_train)\n",
    "    \n",
    "    return SVC_Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test):\n",
    "    \"\"\"Calculating evaluation metrics for model\n",
    "\n",
    "    Args:\n",
    "        model\n",
    "        X_test \n",
    "        y_test \n",
    "\n",
    "    Returns:\n",
    "        model_metrics: dictionary of accuracy, precision and recall scores\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    model_metrics = {} \n",
    "    model_metrics[\"Accuracy\"] = metrics.accuracy_score(y_test, y_pred)\n",
    "    model_metrics[\"Precision\"] = metrics.precision_score(y_test, y_pred)\n",
    "    model_metrics[\"Recall\"] = metrics.recall_score(y_test, y_pred)\n",
    "    return model_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(folder, model, metrics):\n",
    "    \"\"\"Saves model and associated metrics in file specified by folder.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        os.mkdir(folder)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    os.chdir(folder)\n",
    "    joblib.dump(model,\"model.joblib\")\n",
    "    with open(\"metrics.json\", \"w\") as outfile:\n",
    "        json.dump(metrics, outfile)\n",
    "    os.chdir(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    root = os.getcwd()\n",
    "    df = pd.read_pickle(\"cleaned_data.pkl\") # import dataset\n",
    "    df_merged = encode_categorical_features(df) # encode categorical features\n",
    "    stroke = df_merged[\"stroke\"] # separate label from features\n",
    "    df_merged = df_merged.drop(\"stroke\", axis = 1)\n",
    "    X_train, X_test, y_train, y_test = split_data(df_merged, stroke) # split dataset and stratify on stroke column\n",
    "    oversample = SMOTE() # init SMOTE instance \n",
    "    X_train, y_train = oversample.fit_resample(X_train, y_train) # resample the training data\n",
    "    pd.DataFrame(X_train, y_train).pivot_table(index='stroke', aggfunc='size').plot(kind='bar', title='Verify resampling') # verify that SMOTE has correctly oversampled the minority class\n",
    "    model = train_svm(X_train, y_train) # train SVM model\n",
    "    eval_dict = evaluate_model(model, X_test, y_test)\n",
    "    save_model(\"smote_oversampling\", model, eval_dict)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stroke_prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
